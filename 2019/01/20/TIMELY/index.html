<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="datacenter transport,congestion control,RDMA," />










<meta name="description" content="&amp;lt;a id=”download” https://conferences.sigcomm.org/sigcomm/2015/pdf/papers/p537.pdf&amp;quot;&amp;gt;here for paper    Author: Radhika Mittal  (UC Berkeley)     datacenter transport,delay-based congestion">
<meta name="keywords" content="datacenter transport,congestion control,RDMA">
<meta property="og:type" content="article">
<meta property="og:title" content="TIMELY">
<meta property="og:url" content="http://yoursite.com/2019/01/20/TIMELY/index.html">
<meta property="og:site_name" content="miqianmimi Ma">
<meta property="og:description" content="&amp;lt;a id=”download” https://conferences.sigcomm.org/sigcomm/2015/pdf/papers/p537.pdf&amp;quot;&amp;gt;here for paper    Author: Radhika Mittal  (UC Berkeley)     datacenter transport,delay-based congestion">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图1.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图2.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图3.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图4.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图5.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图6.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图7.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/公式1.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/算法1.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图8.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/公式2.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/公式3.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图9.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图10.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图11.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图12.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/表1.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图13.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图14.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图15.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图16.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图17.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图19.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图20.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图21.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图22.png">
<meta property="og:image" content="http://yoursite.com/2019/01/20/TIMELY/图23.png">
<meta property="og:updated_time" content="2019-01-22T11:54:46.513Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TIMELY">
<meta name="twitter:description" content="&amp;lt;a id=”download” https://conferences.sigcomm.org/sigcomm/2015/pdf/papers/p537.pdf&amp;quot;&amp;gt;here for paper    Author: Radhika Mittal  (UC Berkeley)     datacenter transport,delay-based congestion">
<meta name="twitter:image" content="http://yoursite.com/2019/01/20/TIMELY/图1.png">




<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/2019/01/20/TIMELY/"/>





  <title>TIMELY | miqianmimi Ma</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">miqianmimi Ma</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      

    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/01/20/TIMELY/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="YiqingMa">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="miqianmimi Ma">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">TIMELY</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-20T15:47:35+08:00">
                2019-01-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/paper/" itemprop="url" rel="index">
                    <span itemprop="name">paper</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2019/01/20/TIMELY/" class="leancloud_visitors" data-flag-title="TIMELY">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
                <span>℃</span>
             </span>
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv">Readers <i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>人
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p style="color:MediumSeaGreen;font-size:16px;font-family:Comic Sans MS">  &lt;a id=”download” <a href="https://conferences.sigcomm.org/sigcomm/2015/pdf/papers/p537.pdf&quot;&gt;" target="_blank" rel="noopener">https://conferences.sigcomm.org/sigcomm/2015/pdf/papers/p537.pdf&quot;&gt;</a><i class="fa fa-pencil fa-lg"></i><span>here for paper</span> </p>

<ul>
<li>Author: <code>Radhika Mittal</code>  (UC Berkeley)</li>
<li><p style="color:MediumSeaGreen;font-size:16px;font-family:Comic Sans MS">    datacenter transport,delay-based congestion control; os-bypass; RDMA </p>

</li>
</ul>
<hr>
<a id="more"></a>
<h2 id="0-摘要："><a href="#0-摘要：" class="headerlink" title="0.摘要："></a>0.摘要：</h2><p>数据中心的传输协议希望尽可能降低网络延迟，并且提升网络带宽。在本文中，作者展示了数据包延迟最简单的测量方式，是在端上测量RTT时间，不需要任何交换机的反馈，这是一个最有效的拥塞信号。</p>
<ul>
<li>第一，作者展示了NIC硬件的进步，使得RTT微秒精度的测量成为可能，并且用这些RTT足以用来评估交换机队列占用。</li>
<li>然后，作者描述了TIMELY，怎样使用RTT梯度来调整传输速率，来确保在提供高带宽的同时保持较低的数据包延迟<br>在具有OS-bypass功能的NIC上运行的，主机端软件中实现我们的设计。作者在Clos网络拓扑上，使用多达数百台计算机做实验，证明了它的出色性能：打开TIMELY，在带有PFC结构上，进行OS-bypass消息传递，降低了99％的尾端延迟，并且维持了接近线性的吞吐量，相比原来，这一延迟指标提升了9倍。</li>
</ul>
<p>不仅如此，系统远超在，优化内核中运行的DCTCP，将尾部延迟减少了13倍。据我们所知，TIMELY是第一个用于数据中心的基于延迟的拥塞控制协议，它能达到很好的效果，尽管它相比，早期基于延迟的方案，例如Vegas，少了一个有序震级的RTT信号（由于NICoffload的原因）。</p>
<blockquote>
<p>关键词：数据中心传输协议，基于延迟的拥塞控制，OS-bypass(操作系统旁路），RDMA</p>
</blockquote>
<hr>
<h2 id="1-引入："><a href="#1-引入：" class="headerlink" title="1.引入："></a>1.引入：</h2><p>( 数据中心网络运行的计算任务，必须对用户的需求做出足够快的响应，<em>（例如，数千个端计算机需要对用户的这一请求做出反应，必须保证所有传输足够快地完成，才能在100毫秒内满完成这一用户需求)。</em>为了满足这些要求，数据中心传输必须同时提供高带宽（“Gbps”）和低延迟（“msec”）的利用率。其中，低延迟尤其重要，因为即使是一小短时间的延迟，也可能造成涟漪效应，极大降低应用程序性能。因此，数据中心传输必须严格限制延迟和数据包丢失。）</p>
<p>由于传统传输协议不能满足数据中心的严格要求。新的数据中心传输协议，通常选择利用网络的一些信息，提供拥塞的程度表示（例如，DCTCP使用ECN），或者引入流的抽象，来最小化延迟时间，或者将调度交给中央控制器，等等。而作者试图寻找一种更简单，可立即部署的设计。</p>
<p>我们搜索的关键是拥塞信号，理想的拥塞信号有以下几个属性。(1).能够快速通知发件人，拥堵程度的信息。(2).它必须有足够的辨识力，能在具有多个流量类的复杂环境中运行。(3).它部署起来很容易。</p>
<p>（ 惊讶的是，对一些众所周知的网络信号参数做适当调整，就可以满足所有需求，这就是<code>RTT延迟指标</code>。 RTT是一种高细粒度的拥塞测量方法，并且，RTT容易获得，伴随着每次ACK的到来而来。它有效地支持多个流量类别，为排队排在高优先级传输之后的低优先级传输，提供了一种测量方式。此外，它不需要交换机的支持。）</p>
<p>从TCP Vegas开始，延迟就开始成为研究的焦点，一些现代的TCP变量使用延迟指标来估计。但这种延迟的使用有一些问题，</p>
<ul>
<li>基于延迟的方案，在与一些更积极的基于丢失的方案做竞争时，表现不佳。</li>
<li>由于主机和网络问题，延迟估计可能非常不准确<br>因此，延迟经常经常和其他指标（例如丢包）一起使用，采取混合方案中。</li>
</ul>
<p>此外，延迟尚未用作数据中心的拥塞信号，是因为数据中心的RTT，难以用微秒粒度进行测量。在DCTCP中，就避开了基于延迟的测量，并且声称“准确测量队列延迟的小幅度增额是一项艰巨的任务。”</p>
<p>作者观察到，最新的NIC已经能够允许足够的精细度测量数据中心RTT。具体表现在以下几点</p>
<ul>
<li>最新的NIC可以高精度地标出时间戳。</li>
<li>硬件生成的ACK也支持自动消除，不可预测的主机响应延迟时间。</li>
<li>同时，数据中心软件可以做到避免与不同传输协议之间的竞争，多个路径具有类似的，较小的传播延迟。</li>
</ul>
<p>在这篇文章中，作者提出了基于延迟的拥塞控制，这一机制在数据中心中显示出了优异的性能。文章最重要的贡献包括：</p>
<ul>
<li>（1）通过实验，论证了NIC测量的多位RTT信号与网络队列的强相关性。</li>
<li>（2）提出了TIMELY(Transport Informed by MEasurement of LatencY)：一个基于RTT的拥塞控制机制。TIMELY使用速率控制，设计用于多数据包段的NICoffload，以获得高性能。不像早期的一些机制（给队列的RTT设定一个固定阈值）。这边使用RTT速率的变化（梯度）来预测拥塞的程度，以此保证数据中心的高带宽，低延迟。</li>
<li>（3）评估了TIMELY以及OS-bypass的消息操作，使用Clos拓扑结构网络上的数百台机器。在具有PFC（优先级流控制）的结构上及时打开RDMA传输，可将99%的尾部延迟降低9倍。此尾部延迟比在优化内核中运行的DCTCP低13倍。</li>
</ul>
<hr>
<h2 id="2-数据中心拥塞指标RTT的值："><a href="#2-数据中心拥塞指标RTT的值：" class="headerlink" title="2.数据中心拥塞指标RTT的值："></a>2.数据中心拥塞指标RTT的值：</h2><p>现有的数据中心协议，使用交换机得到的信息指标，来观察拥塞的程度，并且以低延迟，低损耗运行。作者认为，基于RTT测量的网络队列延迟，可以不需要交换机的指标，是一个更优越的拥塞指标。</p>
<h3 id="2-1-RTT直接反应延迟"><a href="#2-1-RTT直接反应延迟" class="headerlink" title="2.1 RTT直接反应延迟"></a>2.1 RTT直接反应延迟</h3><p>RTTs非常有价值因为它直接测量了最为重要的指标：因为网络队列堆积引起的端到端延迟时间。来自队列的一些别的指标（例如ECN）无法直接得到这个延迟时间。包上的ECN标记，仅表示对应于该包的队列占用超过了阈值。【在数据中心中丰富地使用QoS，意味着无法将此阈值转换为单个对应的阈值。？？？】</p>
<p>具有不同优先级的多个队列共享同一个输出链路，但ECN标记，仅仅提供超过阈值的那些信息。<code>低优先级流量可能经历较大的队列延迟时间，但它的队列占用并不一定很大（不达到ECN标记的阈值）。因为在这种情况下，队列延迟时间反映了网络中的拥塞状态，但低优先级流量的队列占用并不能反映这种拥塞。</code></p>
<p><code>更进一步，ECN标记仅仅描述了一个单一交换机的行为。在高度利用的网络中。拥塞发生在多个交换机上，ECN标记并不能很好地分清楚他们。RTT积累端到端路径的全部信息。包括NIC在内，也可能成为拥塞的源头，但这种情况基本被所有机制所忽略。</code></p>
<p>最后，RTT甚至适用于支持FCoE的无损网络结构。在这些结构中，由于用于确保零丢包的PFC优先流控制机制，仅仅队列占用可能无法反映拥塞。<code></code></p>
<h3 id="2-2-RTT可以被精确测量"><a href="#2-2-RTT可以被精确测量" class="headerlink" title="2.2 RTT可以被精确测量"></a>2.2 RTT可以被精确测量</h3><p>一个最重要的实践障碍是，<code>RTT是否可以在数据中心准确测量</code>，因为通常数据中心中的RTT，比其他网络中的延小1000倍。而且许多因素阻碍了确测量：</p>
<ul>
<li>由于内核调度引起的可变性; </li>
<li>NIC性能技术，包括offload（GSO / TSO，GRO / LRO）;</li>
<li>协议处理，如TCP晚到的ACK。<br>在数据中心，这些问题每一个都非常严重，其中每个因素都大到覆盖该传播和排队延迟时间。</li>
</ul>
<p>幸运的是，最近NICs从硬件上提供了这些问题的解决方案，可以准确地记录包传输和接收的时间，而不受软件引起的影响。必须小心使用这些方法，以免对NIC过度征税。我们在本文后面描述了NIC的支持。这些NICs也提供了硬件支持的ACK。</p>
<p>综上，这些特征的结合让我们能够准确测量RTT，并且精确地追踪端到端网络队列。</p>
<p>以下的实验结果证明了这些行为：我们用10-Gbps的链路将两台主机连接到同一网络，并发送16KB的ping-pong消息，在静止网络上没有任何交叉流量。由于没有拥塞，我们希望RTT测量值低且稳定。图1比较了使用NIC硬件时间戳，测量的RTT的CDF，以及通过OS TCP协议栈测量的RTT。使用NIC时间戳的RTT的CDF几乎是一条直线，方差很小。相比之下，由内核TCP测量的RTT的值和方差均偏大。<code></code><br><img src="/2019/01/20/TIMELY/图1.png" alt=""></p>
<blockquote>
<p>说明NIC上测量的RTT相比自带的TCP测量的要精准许多；</p>
</blockquote>
<h3 id="2-3-RTT-是一个快速、多位信号："><a href="#2-3-RTT-是一个快速、多位信号：" class="headerlink" title="2.3 RTT 是一个快速、多位信号："></a>2.3 RTT 是一个快速、多位信号：</h3><p>网络队列延迟，可以通过从RTT中减掉已知的传播延迟和序列化延迟求得。奇怪的是，作者发现这个方法，相比ECN，提供更多、更快的关于网络中交换机的信息，ECN作为一个二进制数值（非0即1）, ECN标记传达单个比特的信息，而RTT传达多个比特的信息，并获得多个交换机上，端到端队列延迟。由于每个包都可以携带ECN标记，因此一串ECN标记的序列，可以间接传达，关于拥塞级别的多比特信息是合理的，正如DCTCP中所做的那样。【但是，64KB分段offload？？？】等做法会破坏标记的独立性，因为主机端会突发性的burst。巨大的burst倾向于看到大多数数据包，同时高于或低于标记阈值。</p>
<p>假设它是准确的，测量得到一个较高的RTT，立即表明网络的拥塞程度。对于一个网络链路中的burst，测量它的RTT的方式如下，在burst中的最后一个包的RTT，是整个burst中最大的RTT值。为了显示RTT网络队列延迟的程度，我们模拟了一个incast的环境如下：10台客户端同时产生传输到单个服务器的100个流。为了整合NIC【的offloadoffload？？？】，我们发送64KB消息，并在客户端只收集一个单独的RTT。瓶颈链接是10台机器到服务器的，那一条10Gbps的链接。我们每隔一微秒对交换机上的队列进行采样。</p>
<p>在图2中，展现了测量所得的RTT的CDF，以及在交换机上测量的队列占用的CDF，从图中可以看出，这两个CDF非常匹配。<br><img src="/2019/01/20/TIMELY/图2.png" alt=""></p>
<p>其实，ECN信号与RTT并不强相关，因此与队列占用无关。设计了和前者类似的incast实验，除了现在TCP发送器执行长传输到单个接收器。瓶颈处是每台端发送器到接收器的10Gbps的网络链路，具有80KB交换机ECN标记阈值。使用SND_UNA的推进标记RTT回合的结束，检测发送者，在RTT时间内，给包打上ECN标记的比率大小。我们还测量了每一轮中的最小RTT样本，因为之前的工作都认为这个指标很强大，不受延迟的ACK和发送/接收offload的影响。图3中的散点图和方框图，显示了ECN标记和RTT之间的弱相关性。</p>
<p><img src="/2019/01/20/TIMELY/图3.png" alt=""></p>
<h3 id="2-4-RTT-的限制："><a href="#2-4-RTT-的限制：" class="headerlink" title="2.4 RTT 的限制："></a>2.4 RTT 的限制：</h3><p>作者发现RTT有价值，但有效的设计是必须的。RTT测量可能是沿着网络中的两条路径。ACK并不能辨别它经历的是反向路径拥塞，还是前向路径拥塞。一个简单的解决方法是发送具有更高优先级的ACK，以便它们不会因为排队而延迟。该方法适用于主要在一个方向上发送数据的流的常见情况。</p>
<p>我们进行了一项实验来验证给ACK设置优先级的效果：我们启动了两个incast（主要和次要），使得主要的与次要的incast共享相同的拥塞队列，如图4所示。</p>
<p><img src="/2019/01/20/TIMELY/图4.png" alt=""></p>
<p>【图5主要分析了三种情况：？？？<em>这一段都不懂</em>】</p>
<ul>
<li>1）在ACK的路径中没有拥塞（没有第二次incast）;</li>
<li>2）在ACK路径中存在拥塞; </li>
<li>3）来自主要incast的ACK优先于更高的反向拥塞的QoS队列<br>我们发现反向拥塞，在RTT测量中，产生噪声并延长尾端延迟。主要incast的吞吐量也受到影响（因此较低百分位数的RTT较小）。通过给ACK划分优先级的做法，无法区分在主要incast下测量到的RTT，与没有反向路径拥塞的RTT。<br><img src="/2019/01/20/TIMELY/图5.png" alt=""><br>未来的工作可以是，通过在包中加入时间戳（例如，TCP时间戳）来计算两个包之间的单向延迟的变化。然后，队列延迟时间的变化是到达时间的变化减去每个包的发送时间。这种方法只需要以相同速率运行的时钟，这个比同步时钟的要求松许多，因而也比较好实现。</li>
</ul>
<p>RTT的另一个经典缺点，是改变网络路径会面临不同的网络延迟。但它在数据中心中并不成为问题，因为所有路径都具有较小的传播延迟。</p>
<hr>
<h2 id="3-TIMELY-结构"><a href="#3-TIMELY-结构" class="headerlink" title="3. TIMELY 结构"></a>3. TIMELY 结构</h2><p>TIMELY提供速率控制框架，（该框架独立于可靠性传输协议）。图6显示了它的三个组成部分</p>
<ul>
<li>1）用于监控网络拥塞的RTT测量; </li>
<li>2）将RTT信号转换为目标发送速率的计算引擎; </li>
<li>3）控制引擎，在包之间插入延迟以实现目标速率。<br>我们在具有NIC硬件支持的主机软件中实现TIMELY，并独立运行每个流的实例。<br><img src="/2019/01/20/TIMELY/图6.png" alt=""></li>
</ul>
<h3 id="3-1-RTT的测量"><a href="#3-1-RTT的测量" class="headerlink" title="3.1 RTT的测量"></a>3.1 RTT的测量</h3><p>作者根据图7定义了RTT，图7显示了发送包裹的时间线图：由多个数据包组成的busrt，将其作为一个完整的单位，来计算ACK，具体算法是，从发送第一个数据包（tsend）到接收到ACK（tcompletion）的时间被定义为整个burst的完成时间，这与TCP的算法（每一个数据包就计算一个RTT）有所不同。</p>
<p>此外，延迟由以下几部分组成：</p>
<ul>
<li>1）传输中所有数据包段的序列化延迟，通常高达64 KB。</li>
<li>2）传输数据的RTT时间，以及其ACK在数据中心传播的时间。</li>
<li>3）接收器生成ACK的时间。</li>
<li>4）正反两个方向上的交换机队延迟时间。<br><img src="/2019/01/20/TIMELY/图7.png" alt=""></li>
</ul>
<p>第一部分，可以由段的大小和NIC的线速率决定，可以从总时间中减去。<br>第二部分，传播延迟时间，它又被称作最小RTT，并且对于给定流，数值是固定的，也可以减去。<br>第三部分，因为采用基于NIC的ACK，所以这个值足够接近零，可以忽略。<br><code>第四部分</code>，队列延迟时间，也是导致了RTT变化的原因，这是我们检测拥塞的重点对象。<br>总之，TIMELY将RTT，如下定义：<br><img src="/2019/01/20/TIMELY/公式1.png" alt=""></p>
<blockquote>
<p>此外，还需注意以下指标：<br>（1）<code>ACK的时间戳</code>，由NIC提供，这一完成时间戳指标 <code>tcompletion</code>。因为由OS提供的时间戳受到诸如调度和中断之类的变化的影响不精确，所以采用了NIC提供的时间戳指标。</p>
</blockquote>
<blockquote>
<p>（2）<code>tsend</code>是在将一段数据传输到NIC之前，由读取产生的时间。</p>
</blockquote>
<blockquote>
<p>（3）<code>ACK的生成</code> 采用基于NIC生成ACK，以便我们可以忽略接收器的周转时间。</p>
</blockquote>
<h3 id="3-2-速率计算引擎"><a href="#3-2-速率计算引擎" class="headerlink" title="3.2 速率计算引擎"></a>3.2 速率计算引擎</h3><p>该组件实现了基于RTT的拥塞控制算法，详见§4。速率计算引擎的接口很简单。RTT测量引擎以微秒为单位向速率计算引擎提供RTT，这是仅有的输入，附加的一些时间信息也可能有一定用处。</p>
<h3 id="3-3-速率控制引擎"><a href="#3-3-速率控制引擎" class="headerlink" title="3.3 速率控制引擎"></a>3.3 速率控制引擎</h3><p>当准备发送消息时，速率控制引擎将其分成若干段以进行传输，并依次将每个段发送到调度程序。为了提高运行效率，作者实现了一个处理所有流的调度程序。调度器使用段大小，流速（由速率计算引擎提供）和最后一个包的传输时间，来计算当前段的发送时间，并将该段放入调度程序中的优先级队列中。首先将数据批处理为64 KB段，然后调度程序会计算在两个这样的批处理段之间，插入多少【调步延迟（pacing delay）??？】。</p>
<p><code>段落总结</code>：TIMELY是基于速率而不是基于窗口的，它可以更好地控制流burst，因为广泛使用NIC-offload。数据中心的少量包裹burst的情况下，窗口不能够提供对数据包传输的细粒度控制。但是通过指定目标速率，可以很容易地控制burst之间的时间间隔。</p>
<hr>
<h2 id="4-TIMELY-拥塞控制"><a href="#4-TIMELY-拥塞控制" class="headerlink" title="4.TIMELY 拥塞控制:"></a>4.TIMELY 拥塞控制:</h2><p>拥塞控制算法在速率计算引擎中实现。在本节中，将描述<strong>实验环境和关键性能指标，以及基于梯度的拥塞控制算法。</strong></p>
<h3 id="4-1-度量和设置"><a href="#4-1-度量和设置" class="headerlink" title="4.1 度量和设置"></a>4.1 度量和设置</h3><p>基于经常出现的burst网络负载，数据中心网络环境的需求是高带宽，低延迟。这与传统的广域互联网在很多方面都不同。    在带宽充足的情况下，流的完成时间是最重要的考虑因素，以远程过程调用(Remote Procedure Call)为例。</p>
<ul>
<li>对于较短的RPC，最小完成时间由传播延迟和序列化延迟共同决定。因此，我们尝试最小化队列延迟，来保证较低的RTT。（尾端延迟这一个指标，尤其重要，因为即使一小部分数据包迟到，应用程序的性能也会下降。）这意味，需要满足，低队列延迟和接近零丢包，这两个需求。</li>
<li>对于较长的RPC,由于传输更多数据所需时间更长，所以较长的RPC将具有更长的完成时间，必须保持较高的总吞吐量，以使所有流受益，并保证流之间的公平性。</li>
</ul>
<p>我们评估的主要指标是<code>尾端(第99百分位处)RTT</code>和<code>聚合吞吐量</code>，因为它们共同决定了完成短期和长期RPC的速度快慢。当吞吐量和数据包RTT之间存在冲突时，我们倾向于以牺牲少量带宽来保持较低的RTT。这是因为带宽充足，RTT的增加将直接影响，短RPC的完成时间。次要指标是<code>公平</code>和<code>损失</code>。最后，为了实现可预测的性能，更倾向于稳定的设计，所以更关注于震荡速率，而不是高平均值。</p>
<h3 id="4-2-基于延迟梯度的策略"><a href="#4-2-基于延迟梯度的策略" class="headerlink" title="4.2 基于延迟梯度的策略"></a>4.2 基于延迟梯度的策略</h3><h4 id="相关算法"><a href="#相关算法" class="headerlink" title="相关算法"></a><code>相关算法</code></h4><p>【基于延迟的拥塞控制算法，如FAST TCP和Compound TCP，受到TCP Vegas的开创性工作的启发。它们均以RTT增加超过基线作为拥塞的指标，如果延迟进一步增加则减少发送速率，尝试将瓶颈队列处的缓冲器占用，保持在某个阈值附近。然而，Kelly等人认为当时间比控制环路延迟更短时，不可能控制队列大小。在数据中心中就存在这种情况，其中通过10 Gbps链路的64 KB消息控制环路，延迟至少为51μs，并且可能由于竞争，而显得更高。一个处在队列延迟中的数据包，持续1μs。在这类情况下，大多数算法都选择来，控制队列占用的分布。即使可以控制队列大小，在多个队列成为瓶颈的数据中心网络中选择一个阈值，也是一个难以解决的问题。<br>？？？】</p>
<p>TIMELY的拥塞控制器，采取的指标是，延迟的梯度(或者是队列的时间相关的信息)，而不是维持一个【站立队列？？】。因为可以准确测量RTT的变化，用来表征队列延迟的变化。正延迟梯度表示RTT增加，队列长度上升；而负梯度表示队列在减少。这种策略可以帮助我们实现低延迟。</p>
<p><code>延迟的梯度是瓶颈队列中速率不匹配的代表</code>。我们受到RCP，XCP，PI和QCN的启发，<code>他们发现速率不匹配的显式反馈比，仅基于队列大小的显式反馈，且具有更好的稳定性和收敛性</code>。关键的区别在于所有这些先前的控制器都在网络中的【点队列？？？】中运行，而TIMEL实现了同样的效果，通过使用端到端延迟梯度。</p>
<p>假设模型是，N台主机同时以y(t)速率给同一条瓶颈链路发送数据，瓶颈链路的处理速率是C，发出的速率是&lt;=C，注意到在瓶颈链路处的队列延迟是q(t)。如果y(t)&gt;C,那么队列堆积的速度就是y(t)-C。那么队列延迟的梯度就是y(t)-C/C。梯度没有量纲。因此，通过RTT信号测量的延迟梯度可以充当瓶颈链路处的速率不匹配的指标。只要网络中存在一些非零队列，这种推理就成立。当零排队或队列的大小没有变化时，测量的梯度也为零。TIMELY做的就是希望将流入速率y(t)和处理速率C匹配起来。</p>
<h3 id="4-3-核心算法"><a href="#4-3-核心算法" class="headerlink" title="4.3 核心算法"></a>4.3 核心算法</h3><p>算法1中，显示了拥塞控制算法的核心伪代码。TIMELY对于每个链接，维持了一个单独的速率R(t)，并且使用RTT样本，在每次任务完成后，进行一次更新。它采用梯度追踪，使用平滑的延迟梯度作为误差信号，来调整速率，以使吞吐量接近可用带宽。此外，使用了阈值，对带宽利用率低或数据包延迟过高，等特殊的情况作出响应。<br><img src="/2019/01/20/TIMELY/算法1.png" alt=""></p>
<p>图8显示了梯度策略以及两个阈值的关系。当RTT处于标准工作范围时，通过梯度跟踪算法来调整发送速率。<br><img src="/2019/01/20/TIMELY/图8.png" alt=""></p>
<p><strong>计算延迟的梯度</strong></p>
<p>依赖于NIC上的时间戳来计算RTT，并且根据两个连续的RTT样本的差值，来计算延迟梯度。用最小的RTT来做标准化。在实际操作中，最小RTT的值是否精确并不影响最后效果，因为最主要的事确定队列在堆积还是消失。因此，采用固定值来表示数据中心的传播延迟。最终，把结果输入EWMA过滤器。这个过滤器的作用是可以观察到队列的上升或者下降趋势，同时忽略一些与拥塞无关的小的队列长度波动。</p>
<p><strong>计算发送速率</strong></p>
<p>然后，TIMELY使用标准化后的梯度来计算连接目标速率R(t)。</p>
<ul>
<li>如果梯度是负值，或者接近于0，这说明，网络可以应付总的传入速率，因此速率有提升的空间。TIMELY在这种情况下，对链接速率做出如下改变R=R+△，其中△是带宽的additive增量常数。</li>
<li>如果梯度是正值，这表明发送速率当过网络的能力，因此TIMELY会采用multiplicative乘法率递减量B，并且用梯度来调整目标速率如下：<br><img src="/2019/01/20/TIMELY/公式2.png" alt=""></li>
</ul>
<p>基于总输入和输出速率的延迟梯度信号，对于同一条拥塞路径的所有连接是相同的。众所周知的AIMD 性质保证了算法能获得各链接之间的公平性。根据如上算法，以较高速率发送的连接，其速率的降低也较强，而所有连接的速率增量保持相同。</p>
<p><strong>RTT低阈值-Tlow-</strong></p>
<p>【最为理想的实验环境，包裹发送的节奏是完美的。？？？】然而，在实际操作中，TIMELY的速率控制策略在&lt;=64KB的段上执行，较大的段会导致burst，产生短暂的队列堆积，并接连导致RTT突然增加到峰值。如果没有Tlow这个RTT的低阈值的话，核心算法会检测到一个个RTT的峰值，较大的正延迟梯度，并指示拥塞，来极大减少发送速率。而这种行为其实是不必要的。因此，可以通过设置一个TlowRTT低阈值，来过滤这种RTT的突增情况。对于大于这个阈值的RTT样本，才开始使用延迟梯度调整速率的策略。</p>
<p><strong>RTT高阈值-Thigh-</strong></p>
<p>梯度算法的预期是能够在，保持接近瓶颈链路吞吐量的情况下，构建很低的队列。然而理论上存在一种情况，队列占用很大，但是维持不变，在这种情况下，梯度也保持为零。为了避免这种情况，Thigh作为一个端到端网络队列延迟的可容忍的上限，它通过一种与梯度无关的方式来降低速率，这是一种保护操作。如果测出的RTT高于Thigh，则按照如下公式降低速率：<br><img src="/2019/01/20/TIMELY/公式3.png" alt=""><br>注意到，公式中使用的是瞬时而不是平滑的RTT。虽然这看起来很不寻常，但这么做，可以减缓对单个过大的RTT的响应速度，因为它最后会发出拥塞信号，优先是保持低延迟并且避免包丢失。（作者也尝试过将平均RTT作为拥塞指标进行响应，并发现这么做会损害数据包延迟时间，当平均RTT上升，拥塞控制降低速率时，网络中的排队延迟已经增加了)。我们在§6中展示了Thigh与吞吐量-延迟权衡曲线的关系。</p>
<p><strong>激进增加HAI(Hyperactive increase)为了更快的收敛</strong></p>
<p>因为受到TCP BIC中的最大探测阶段所启发，CUBIC拥塞控制算法以及QCN，我们包括一个HAI选项，以实现更快的收敛。下面是它操作的流程：如果TIMELY在经过一段缓慢增长后没有达到新的公平共享的平衡点，那么梯度在几个连续完成时间内均为负值，则HAI会启动，速率可以更快的增加，其中rate增加N△而不是△。</p>
<h3 id="4-4-梯度-VS-队列大小"><a href="#4-4-梯度-VS-队列大小" class="headerlink" title="4.4 梯度 VS 队列大小"></a>4.4 梯度 VS 队列大小</h3><p>在实验中，具体分析了基于梯度的策略和基于队列大小策略的不同。如果将Tlow和Thigh的值大小设置为相同的，那么TIMELY的拥塞控制将退化成为基于队列大小的策略（类似TCP FAST 算法），将Ttarget设置成唯一的RTT阈值，这一数值加性增加，乘性递减（additively increased, multiplicately decreased）。</p>
<p>图9中比较了基于梯度和基于队列大小，这两种不通过策略下，处理incast流时的带宽和延迟的性能好坏。可以看到，基于队列大小的方法可以维持低延迟，或者高带宽，但很难同时满足两者。（建立一个RTT阈值较高的standing queue，带宽可以达到最大化，然而延迟就会受损；相反的，建立一个RTT阈值较低的standing queue，延迟可以最优，但带宽就不能得到保证，因为队列经常是空的）；<code>而基于延迟梯度的算法</code>可以侦测到队列的变化，从而提前预测了拥塞的情况，因此使得这种策略可以在保持网络高带宽利用率的同时，达到较低的尾端延迟水平。<br><img src="/2019/01/20/TIMELY/图9.png" alt=""><br>更进一步来说，如图10中所示，在基于队列大小的策略中，速率的抖动较为严重，因为这种算法要求，根据队列大小，来微调RTT的升降。而基于梯度的算法，在公平保持公平分享带宽的同时，维持了一个较为稳定的速率。<br><img src="/2019/01/20/TIMELY/图10.png" alt=""><br>Tlow以及Thigh的阈值限制，有效地使延迟维持在一个目标范围内，并且间接地实现了，类似AQM机制中的目标队列占用量的方法。总之，使用延迟梯度的策略增强了稳定性，并且使得延迟维持在目标范围内。</p>
<hr>
<h2 id="5-实际应用"><a href="#5-实际应用" class="headerlink" title="5. 实际应用"></a>5. 实际应用</h2><p>实际操作中，使用基于10Gbps的支持OS-bypass功能的NIC，该NIC支持多包分段，并且反馈基于硬件的ACKs以及时间戳。我们运用TIMELY支持RDMA。（利用RDMA特性将操作的负载转移到NIC上，具体操作如下：使用RDMA的读写操作将消息从主机端内存，以数据包形式发送到网络中。在远程主机上，NIC接收到发送来的消息，并且将它放在远端主机内存中，可供远端应用直接使用。当传输完成后，主机端会接受到通知。）以下，描述操作中一些值得注意的细节。</p>
<h3 id="5-1-传输界面"><a href="#5-1-传输界面" class="headerlink" title="5.1 传输界面"></a>5.1 传输界面</h3><p>TIMELY只关注传输协议的拥塞控制部分;它不关心应用程序的可靠性或高级别的接口，这允许协议处理的接口端十分简单：只需要提供消息发送和接收。当发送端提供一个大消息包时，TIMELY将其分解成很多小部分的段。一个大消息包可以被分解成一组有顺序的序列包，并且被传输到NIC，通过burst的形式发送到网络中。在远端主机上，NIC承认收到完整的数据段信息，在接收端处，一个数据段被接受，并且传输到传输组的其他部分被处理时，这个简单的模型支持从RPC到TCP字节流等的传输。</p>
<h3 id="5-2-使用NIC完成进行RTT的测量"><a href="#5-2-使用NIC完成进行RTT的测量" class="headerlink" title="5.2 使用NIC完成进行RTT的测量"></a>5.2 使用NIC完成进行RTT的测量</h3><p>实际操作中，使用NIC时间戳是十分具有挑战性的事情。NIC只记录绝对时间戳，换句话说它只负责记录多宝传输的操作完成的时间，因此需要用户软件自己记录操作被发送到NIC上的时间点。这需要一个机制，用作把主机端的时钟映射到NIC上的时钟，还要实现校准操作。除了记录CPU主机端，将job发送到NIC的时间，并建立一个校准机制把主机端的时钟映射到NIC上的时钟。简单的线性映射就已经足够满足要求了。图11中对比了根据NIC HW的时间戳和校准机制获得的RTTs，以及单纯的应用时间戳算出的RTTs的效果。<br>从图中看出，使用NIC端的时间戳以及校准机制，测得的结果都十分精确。而使用应用端算出的RTTs具有较大的方差，并且这种计算会增加主机端的复杂。<br><img src="/2019/01/20/TIMELY/图11.png" alt=""></p>
<p>作者认为任何产生NIC队列，也可以当成部分的RTT信号。这很重要，因为NIC队列也是网络拥塞的一种表现，并且也可以通过速率控制的机制来处理。</p>
<h3 id="5-3-RDMA速率控制"><a href="#5-3-RDMA速率控制" class="headerlink" title="5.3 RDMA速率控制"></a>5.3 RDMA速率控制</h3><p>对于RDMA写入操作，发送端的TIMELY直接控制了段的发送间隔。对于RDMA读的操作，接收器处理读的请求，并且对远端主机执行一个数据段的DMA操作。在这种情况下，TIMELY不需要直接的控制数据的发送间隔，而是在控制Read操作的间隔。因此，计算引擎会考虑远程读取操作。</p>
<h3 id="5-4-应用限制行为"><a href="#5-4-应用限制行为" class="headerlink" title="5.4 应用限制行为"></a>5.4 应用限制行为</h3><p>应用通常没有足够的数据来使得当前流的传输达到目标速率。当这种情况发生的时候，因为网络没有拥塞，因此不希望不受限制得增加目标速率。为了防止这种问题。在只有应用发送的速率达到超过80%的情况下，才使得目标速率增加，还将最高目标速率限制在10 Gbps。这种预留一些空间的做法，目的是，为了让应用在有足够数据发送的时候，可以增加它的速率，但不发生延迟。</p>
<h3 id="5-5-速率更新频率"><a href="#5-5-速率更新频率" class="headerlink" title="5.5 速率更新频率"></a>5.5 速率更新频率</h3><p>TIMELY的发送速率更新公式确保了在每个RTT间隔中，最多有一个完成的事件。（这个64KB的传输延迟消息在一个10Gbps的链路上是51us，而最小的RTT延迟时间是20us，因而确保了上述条件）然而，对于很小的数据段，在一个RTT的时间间隔中，可能会有很多个完成的事件。在这种情况下，希望根据最新的信息来更新速率。因此，这时采取的是，对每个完成的事件，更新一次速率。</p>
<p>为了提高调度的效率，速率控制引擎不激进地执行速率更新。当之前的计算当前段的发送时间过去后，调度器会检测当前的速率。如果速率降低了，则会重新计算发送时间，合适的话，还可能对数据包重新排序。</p>
<h3 id="5-6-额外的【发送-pacing-？？？】机会"><a href="#5-6-额外的【发送-pacing-？？？】机会" class="headerlink" title="5. 6 额外的【发送 pacing ？？？】机会"></a>5. 6 额外的【发送 pacing ？？？】机会</h3><p>默认来说，NIC是以链路的线速度，通过burst形式发送一段数据，在这里探索了另一种可能性：使用NIC速率限制器以低于链路线速度的速度来传输这一组数据包。基本原理是补充【pacing引擎？？？】，使用硬件速率限制器，可以将部分pacing的负荷转移到NIC上。但是因为硬件限制，每间隔几个RTT时间，就重新配置发送速率基本不可行。使用一种混合方法：<code>软件端处理大型的段数据pacing以及硬件端以固定速率(小于线速率）处理pacing</code>。 在这样的高速率情况下，NIC做pacing的目的是在两个burst之间插入一些间隙，以此解决多重的burst在交换机处重合导致的延迟突增的问题。在这种情况下，速率控制引擎通过把它当做较低的传输线速率，来补偿NICpacing延迟。</p>
<hr>
<h2 id="6-评估"><a href="#6-评估" class="headerlink" title="6. 评估"></a>6. 评估</h2><p>作者在主机端的两种不同规模下，评估了TIMELY的效果：</p>
<ul>
<li>第一种情况是，在一个incast的设置下，评估了诸多网络基础的特性：比如带宽，公平性， 数据包延迟，以及时间的准确性。对于这些微型基准测试，使用带有机架设备的小型测试平台。</li>
<li>第二种情况是，在经典的Clos网络结构下，在数百台机子上，大规模的测试平台下部署TIMELY。<br>有链路均为10 Gbps。所有实验中使用的操作系统都是Linux。</li>
</ul>
<p>作者比较了TIMELY与以下两种不同情况作对比：</p>
<ul>
<li>第一种，测试了在具有优先流控制（PFC）的结构上，并且使用OS-bypass消息传递。（这经常被用于FCoE中的低损耗和延迟，例如DCB）RDMA的传输通过NIC，并且对丢包比较敏感。PFC确保了无丢包，因此对RDMA尤其重要。将TIMELY添加到RDMA的设置中，来观察它的好处；检查PFC暂停消息计数是否很低，来确保有足够的交换机缓存来使TIMELY工作。</li>
<li>第二种，使用优化的内核堆栈，在不使用PFC的情况下，运行DCTCP。选择DCTCP，是因为它是一个众所周知的现代数据中心的传输协议。</li>
</ul>
<p>因此，主要做了以下四类的对比实验：</p>
<ol>
<li>DCTCP，使用没有PFC的结构上的内核DCTCP</li>
<li>PFC，使用PFC结构上，进行OS-bypass消息传递</li>
<li>FAST *，使用具有类似TCP FAST的拥塞控制算法，进行OS-bypass消息传递</li>
<li>TIMELY，使用TIMELY，进行OS-bypass消息传递</li>
</ol>
<p>除非特别提及，TIMELY使用以下参数：</p>
<ol>
<li>数据段大小16KB</li>
<li>Tlow=50us ,Thigh = 500us</li>
<li>additive 增量是10Mbps</li>
<li>multiplicative 减少量是0.8</li>
</ol>
<h3 id="6-1-小规模实验"><a href="#6-1-小规模实验" class="headerlink" title="6.1 小规模实验"></a>6.1 小规模实验</h3><p>在小规模的实验中，使用incast流模式，因为这是数据中心最重要的网络拥塞情况。为了创造这样的incast情形，采用10台机器在一个单一机架上，同时给一台服务器发送数据。每个client运行4个链接，一共40个链接。每个链接发送16 KB字段的速率，实验的瓶颈链路是2x10G的链路。这是测试拥塞控制的理想典型网络环境：虽然数据中心存在数以万计的链接，但因为网络被限制的连接数通常很少。</p>
<h4 id="6-1-1-测量的RTT必须精准："><a href="#6-1-1-测量的RTT必须精准：" class="headerlink" title="6.1.1   测量的RTT必须精准："></a>6.1.1   测量的RTT必须精准：</h4><p>为了评估TIMELY，所需RTT样本的准确性，我们在测量的RTT中添加噪声，并观察其对吞吐量的影响。我们将在[0，x]μs范围内，均匀分布的随机噪声，添加到每个RTT样本中，其中x设置为0,50,100,150,200。图12显示了在不同噪声水平下，服务器上测量的总吞吐量。 50μs的平均噪声会导致可见的吞吐量降低，并且，噪声越高，性能损失就越严重。 Tlow值低于50μs会进一步降低对RTT噪声的容差。因此，NIC支持的准确RTT测量是TIMELY的基石。<br><img src="/2019/01/20/TIMELY/图12.png" alt=""></p>
<h4 id="6-1-2-与PFC做比较："><a href="#6-1-2-与PFC做比较：" class="headerlink" title="6.1.2 与PFC做比较："></a>6.1.2 与PFC做比较：</h4><p><img src="/2019/01/20/TIMELY/表1.png" alt=""><br>表1中比较了使用OS-bypass的TIMELY，和常规的    PFC部署的RDMA。当TIMELY中的带宽十分低的时候，中间和尾端的RTT，低于一定的数量级并且不会触发PAUSE暂停，还显示了TIMELY对单个的链接也有出色的表现。图13显示了对四个单独链接，使用TIMELY后，RTT和吞吐量随时间变化的轴线。每个数据点，代表一个单独的完成的事件。可以看到，4个单独链接的流公平共享带宽，并且将RTT维持在较低的水平。为了数量化测试带宽分配的公平程度，计算了Jain fairness指数，TIMELY的指标达到0.953，而PFC的指标达到0.909。TIMELY的设计可以做到更公平共享带宽。<br><img src="/2019/01/20/TIMELY/图13.png" alt=""></p>
<h4 id="6-1-3-和DCTCP的对比"><a href="#6-1-3-和DCTCP的对比" class="headerlink" title="6.1.3 和DCTCP的对比"></a>6.1.3 和DCTCP的对比</h4><p>将DCTCP和TIMELY做对比。回顾一下DCTCP的做法：发送端发出支持ECN的数据包，交换机给每个队列超过固定阈值的包做上标记，接收器回复所有的ECN标记给发送端，发送端根据窗口中具有ECN标记的包的比例来调整发送的速率。注意到，必须比较两个不同的主机软件堆栈，因为DCTCP在没有PFC支持的优化内核中运行，而TIMELY用于OS-bypass消息传递。由于处理ECN反馈的NIC硬件限制，只能在没有OS-bypass的环境中实施DCTCP。交换机ECN标记阈值设置为K=80KB。这比DCTCP作者建议的K=65数据包用于10Gbps操作要少，因为愿意牺牲少量吞吐量来确保低延迟。表1总结了三次实验结果，RTT分布如图14所示。TIMELY的平均端到端RTT比DCTCP低10倍（60μs对600μs）。更重要的是，尾部延迟下降了近13倍（116μs对1490μs）。且没有观察到丢失PFC包。<br><img src="/2019/01/20/TIMELY/图14.png" alt=""></p>
<h4 id="6-1-3-和TCP-FAST-like算法做对比"><a href="#6-1-3-和TCP-FAST-like算法做对比" class="headerlink" title="6.1.3 和TCP FAST-like算法做对比"></a>6.1.3 和TCP FAST-like算法做对比</h4><p>然后作者将TIMELY和TCP-FAST拥塞控制算法作比较。我们使用TCP-FAST方程来调整pacing速率，而不是周期性地更新拥塞窗口。TCP-FAST可通过协议参数a进行调整，该参数控制带宽的公平性以及网络中的缓冲总量。a是网络中待处理的每个流的数据包数，因为TIMELY是基于速率的，把a转变成吞吐量值。表1显示了具有三个不同a值的结果。对于较小的a=10 Mbps，FAST可以实现较低的尾端延迟 49us，尽管吞吐量显着下降，在20Gbps线速率下仅实现7.5Gbps。对于较大的a=50 Mbps/100 Mbps，TIMELY仍然可以实现更好的吞吐量和延迟权衡。</p>
<h4 id="6-1-4-变化的Tlow"><a href="#6-1-4-变化的Tlow" class="headerlink" title="6.1.4 变化的Tlow"></a>6.1.4 变化的Tlow</h4><p>TIMELY的性能，也受算法参数的影响，从低阈值Tlow开始探索。目的是突出影响阈值的因素，而不是调整参数。低阈值用于在非拥塞网络的情况下，吸收RTT的变化。RTT的变化与最大分段大小相关，随着分段变大，incast时的RTT会增加。图15显示了对于大小为16 KB，32 KB和64 KB的段，瓶颈吞吐量和RTT时间如何随着Tlow的变化而变化。<br><img src="/2019/01/20/TIMELY/图15.png" alt=""></p>
<p>我们看到降低Tlow会降低网络延迟，这是因为较低的阈值，允许更频繁地使用RTT梯度，来调整响应队列变化的速率。但是较低的阈值最终会对吞吐量产生负面影响。对于16 KB的段大小，当incast程度相对较低时，仅50μs的Tlow为我们提供了最高的吞吐量19.4 Gbps。然而，随着我们增加分段大小，并因而提高了incast程度，当Tlow变得太小时，吞吐量迅速下降。对于32 KB的段大小，临界点是100μs的Tlow。对于64 KB段这种最苛刻的情况，临界点在200-300μs之间。如此大的Incast使得很难同时获得高吞吐量和低延迟。</p>
<h4 id="6-1-5-使用细粒度的pacer调整使Burst更平滑"><a href="#6-1-5-使用细粒度的pacer调整使Burst更平滑" class="headerlink" title="6.1.5 使用细粒度的pacer调整使Burst更平滑"></a>6.1.5 使用细粒度的pacer调整使Burst更平滑</h4><p>速率控制引擎引入段之间的pacing延迟，为了更好调整64KB的burstiness，并且启用了NIC offload。作者选择采用细粒度pacing。在这个模型中，除了主机软件pacing之外，NIC硬件还使用pacing来发送数据包。pacing使得数据包在网络中更容易混合。可编程NIC（如NetFPGA）允许执行pacing的使用。例如HULL这样先前的工作也是用了NIC pacing，并且FQ/Pacing等细粒度pacing排队规则在Linux内核中已有实现。</p>
<p>使用64 KB段重复进行实验，这次试用NIC pacing，两个阈值分别为，Tlow=0μs,Thigh =50μs。调整1Gbps的64 KB的数据引入512μs的一个序列化延迟，图16显示了不同NIC pacing速率的结果。</p>
<p><img src="/2019/01/20/TIMELY/图16.png" alt=""><br>【正如预期的那样，由于burstiness降低，导致吞吐量增加和延迟减少，更大的吞吐量增加可以获得更大的pacing。最优的pacing速率是700 Mbps。请注意，这也意味着单流量性能的上限为700 Mbps，除非动态调整调步速率。吞吐量略有下降，延迟时间超过此水平，因为pacing接近公平份额并具有节流效果。？？？】</p>
<p>注意到，在TIMELY设计中，NIC硬件pacing不是绝对的要求;但更确切地说，可以实现在较低的网络尾端延迟和由于软件pacing引起的较高的CPU开销之间权衡。</p>
<h4 id="6-1-6-变化的Thigh"><a href="#6-1-6-变化的Thigh" class="headerlink" title="6.1.6 变化的Thigh"></a>6.1.6 变化的Thigh</h4><p>TIMELY使用一个高阈值，来对更大的RTT来做出更快的反应。这一阈值没有低阈值重要，因为仅对于超大的RTTs起作用。但随着连接变得复杂，RTT突增的可能性变大，这一阈值变得愈发有用。<br><img src="/2019/01/20/TIMELY/图17.png" alt=""><br>图17显示了不同数量的竞争链接下，这一阈值对吞吐量的影响。在一对四（一个客户端对应4个连接）的结构中，99百分位的RTT大约是100μs。这意味着Thigh&gt;100μs几乎没有效果。随着负载增加（每个客户端对应7个连接），99百分位RTT稳定接近200μs。那么，若将Thigh到100us或者更低，RTT会有所下降。当每个客户端对应10个连接时，99百分位RTT大约500μs，Thigh接近于500us，随着Thigh下降，RTT也会减少，对于100us的Thigh，吞吐量非常好。低至最多200μs的Thigh有助于减少尾部延迟，而不会降低吞吐量。</p>
<h4 id="6-1-7-激进增量（HAI）"><a href="#6-1-7-激进增量（HAI）" class="headerlink" title="6.1.7 激进增量（HAI）"></a>6.1.7 激进增量（HAI）</h4><p>HAI有助于更快地获取可用带宽。通过多次不同load的incast实验，来证明这一点。incast从10个客户端和每个客户端10个连接开始。在收敛的初始阶段之后，每个客户端同时关闭其10个连接中的9个，从而将剩余连接的公平分享率提高10倍。图18显示了HAI如何在50ms内，将连接吞吐量从初始公平速率200Mbps提升到1.5Gbps，并在100ms内达到2 Gbps的新公平份额。相反，使用固定的加法增量，在140 ms后吞吐量仅仅到1.5 Gbps。发现选择五个连续RTT攻击作为使用HAI的阈值，这一决定，在模型收敛性和稳定性之间取得了良好的平衡。</p>
<h3 id="6-2-大规模实验"><a href="#6-2-大规模实验" class="headerlink" title="6.2 大规模实验"></a>6.2 大规模实验</h3><p>通过经典Clos拓扑中的几百台机器上的实验，来研究TIMELY的大规模试验。表明TIMELY能够在大型的拥塞网络场景中保持可预测和低延迟。该实验在客户端和服务器对之间生成RPCs。为了测试TIMELY，并且增加burst，我们使用64-KB的段大小和RPC。</p>
<h4 id="6-2-1-最长路径均匀随机"><a href="#6-2-1-最长路径均匀随机" class="headerlink" title="6.2.1 最长路径均匀随机"></a>6.2.1 最长路径均匀随机</h4><p>在此流模式中，客户端从具有网络最长路径的一组服务器中选择服务器。客户端发出64 KB请求。服务器回复相应大小的有效负载。客户端计算了RPC延迟（记录了请求发送到服务器到收到服务器响应的时间）。<br><img src="/2019/01/20/TIMELY/图19.png" alt=""><br>图19显示了应用程序在负载增加的情况下，观察到的标准化吞吐量。网络的饱和点（接受负载小于提供的负载的点）对于TIMELY来说更高，因为它能够通过最小化队列，从而也可以每秒暂停帧，来发送更多流量。<br><img src="/2019/01/20/TIMELY/图20.png" alt=""><br>【<br>图20显示了RTT与负载的关系。与PFC相比，TIMELY将RTT的中位数和99百分位数，分别降低了2倍和5倍。这导致RPC中值相应减少约2倍（如图21所示）。如果没有TIMELY，网络队列会增加，以尝试达到提供的负载。有TIMELY，通过将队列从共享网络移到终端主机，来维持低网络队列。因此，随着提供的负载增加超过饱和点，99％的RPC延迟降低效果会减弱。<br>？？？】<br><img src="/2019/01/20/TIMELY/图21.png" alt=""></p>
<h4 id="6-2-2-网络不平衡-incast"><a href="#6-2-2-网络不平衡-incast" class="headerlink" title="6.2.2 网络不平衡(incast)"></a>6.2.2 网络不平衡(incast)</h4><p>为了强调TIMELY缓解拥塞的能力，设计了一个实验，背景负载是最长路径均匀随机流量，使用三个级别的后台负载：低（0.167），中（0.3）和高（0.5）。图22显示了该实验的正常吞吐量和99百分位的RTT。从图19中可知，在网络达到饱和之前，TIMELY和PFC吞吐量对于均匀随机流量是相同的。当添加一个incast，没有TIMELY，吞吐量下降13％至54％，主要原因是由于PFC产生的线路阻塞。用图22中的RTT测量结果也证实了这一观察结果，TIMELY能够保持队列相对较短，并且防止拥塞扩散，且整体吞吐量保持不变。<br><img src="/2019/01/20/TIMELY/图22.png" alt=""></p>
<h4 id="6-2-3-应用级别的标准"><a href="#6-2-3-应用级别的标准" class="headerlink" title="6.2.3 应用级别的标准"></a>6.2.3 应用级别的标准</h4><p>图23显示了数据中心存储的基准测试，RPC延迟（y轴是对数刻度）。有TIMELY的话，该应用程序能够以更高的利用率行动，应用程序数据延迟的下降，这实际上反映了应用程序在查询执行期间能够维持吞吐量的增加。<br><img src="/2019/01/20/TIMELY/图23.png" alt=""></p>
<hr>
<h3 id="7-相关工作"><a href="#7-相关工作" class="headerlink" title="7. 相关工作"></a>7. 相关工作</h3><p>数据中心拥塞控制是一个深入研究的主题。</p>
<p><code>RED</code>和<code>CoDel</code>的方法是通过提前丢弃数据包，促使发送者降低传输速率，以避免与尾部丢弃相关的大型【站点队列？？？】。但是，丢失仍会导致数据包丢失的流量延迟，为了避免数据包丢失，许多方案依赖于ECN形式的交换机支持，其中数据包被标记为指示拥塞。 ECN标记通常在多个数据包上通过组合，提供细粒度的拥塞信息，但作者已经在实验中表明ECN具有固有的局限性。还有其他提议依赖于交换机的支持来缓解拥塞，例如QCN（细粒度队列占用信息）和pFabric（细粒度优先级划分）。</p>
<p><code>TIMELY</code>属于不同类别的算法，使用延迟测量来检测拥塞，且不需要交换机支持。我们从TCP Vegas，FAST和Compound 中获取灵感。这些提议是基于窗口的，并且保持一个接近最小RTT的队列。相比之下，TIMELY是一种基于速率的算法，采用梯度方法，并且不依赖于最小的RTT。实验表明，NIC可以很好的支持TIMELY。</p>
<p>最近的一个方案<code>DX</code>，确定了将延迟用作高吞吐量和低延迟数据中心通信的拥塞信号的好处。DX使用针对NIC的DPDK驱动程序实现准确的延迟测量，并且拥塞控制算法位于Linux TCP协议栈内。DX算法类似于传统的基于窗口的提议，其附加增加和乘法减少与平均队列延迟成比例。</p>
<p>CAIA Delay Gradient（CDG）提出了一种用于广域网的TCP拥塞控制的延迟梯度算法。其主要目标是确定基于延迟与基于损失的拥塞控制是否可以共存。因此，其算法的性质与TIMELY中的算法不同。</p>
<p>链路层流控制，用于Infiniband和数据中心桥接（DCB）网络中的低延迟消息传递。然而，部分论文记录了优先流控制（PFC）的问题，包括HoL阻塞和暂停传播或拥塞扩散。最近的一些提案旨在通过使用ECN标记来维持PFC，维持低队列占用率来克服这些问题。 <code>TCP-Bolt</code>在内核TCP协议栈中使用修改的DCTCP算法。 <code>DCQCN</code> 结合使用ECN标记和在NIC中实现的基于QCN的基于速率的拥塞控制算法。评估表明它解决了PFC的HoL阻塞和不公平问题，从而使RoCE可用于大规模部署。 <code>TIMELY</code>使用RTT信号，在支持NIC时间戳的主机软件中实现，适用于OS-bypass和基于OS的传输。在拥塞控制和CPU利用率方面，TIMELY和DCQCN的比较是一项有趣的未来工作。</p>
<p>拥塞可以通过使用分布式调度方法或集中式调度方法来避免。然而，这些方案尚未大规模证明，并且比简单的基于延迟的方法更复杂。</p>
<p>最后，负载敏感路由（例如<code>Conga</code>和<code>FlowBender</code>）可以通过将网络流向四周扩散，来缓解拥塞的网络拥塞点，从而提高吞吐量。然而，这些方法仍需要基于主机的拥塞控制来提供匹配的负载。</p>
<hr>
<h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8. 总结"></a>8. 总结</h2><p>传统观点认为延迟是数据中心不可靠的拥塞信号。作者设计了TIMELY，发现结果恰恰相反 - 当适当调整延迟后，RTT与网络中的队列建立密切相关。TIMELYd利用现代NIC支持的时间戳和ACK来执行基于精确RTT测量的拥塞控制。TIMELY可以检测并响应数十微秒的队列，以提供低延迟和高吞吐量，即使存在不频繁的RTT信号和NIC offload也是如此。随着数据中心速度向上扩展一个数量级，未来的工作应该集中在RTT如何继续用于拥塞控制，同时重新考虑基于延迟的算法本质。 </p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/datacenter-transport/" rel="tag"># datacenter transport</a>
          
            <a href="/tags/congestion-control/" rel="tag"># congestion control</a>
          
            <a href="/tags/RDMA/" rel="tag"># RDMA</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/01/20/Reproducing-Network/" rel="next" title="Reproducing-Network">
                <i class="fa fa-chevron-left"></i> Reproducing-Network
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>
  <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/miqianmimi || github" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.facebook.com/100002269882529 || facebook" target="_blank" title="FB Page">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  FB Page
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://instagram.com/miqianmimi || instagram" target="_blank" title="Instagram">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  Instagram
                </a>
              </span>
            
  <!--以下是加入关于high一下的代码-->
            <span class="links-of-author-item"><a title="小high一下~" style="underline: none;color:red" rel="alternate" class="mw-harlem_shake_slow wobble shake" href="javascript:shake()"><i class="fa fa-music"></i> &nbsp;&nbsp;High</a></span>
  <!--以上是加入关于high一下的代码-->
          
        </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="YiqingMa" />
            
              <p class="site-author-name" itemprop="name">YiqingMa</p>
              <p class="site-description motion-element" itemprop="description"><p style="color:MediumSeaGreen;font-size:15px;font-family:Comic Sans MS" > If life deals you lemons, make lemonade. </p></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">18</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">26</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/miqianmimi" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.facebook.com/100002269882529" target="_blank" title="FB Page">
                      
                        <i class="fa fa-fw fa-facebook"></i>FB Page</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://instagram.com/miqianmimi" target="_blank" title="Instagram">
                      
                        <i class="fa fa-fw fa-instagram"></i>Instagram</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://jacquelinewang.github.io/" title="Jacqueline Wang" target="_blank">Jacqueline Wang</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#0-摘要："><span class="nav-number">1.</span> <span class="nav-text">0.摘要：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-引入："><span class="nav-number">2.</span> <span class="nav-text">1.引入：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-数据中心拥塞指标RTT的值："><span class="nav-number">3.</span> <span class="nav-text">2.数据中心拥塞指标RTT的值：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-RTT直接反应延迟"><span class="nav-number">3.1.</span> <span class="nav-text">2.1 RTT直接反应延迟</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-RTT可以被精确测量"><span class="nav-number">3.2.</span> <span class="nav-text">2.2 RTT可以被精确测量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-RTT-是一个快速、多位信号："><span class="nav-number">3.3.</span> <span class="nav-text">2.3 RTT 是一个快速、多位信号：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-RTT-的限制："><span class="nav-number">3.4.</span> <span class="nav-text">2.4 RTT 的限制：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-TIMELY-结构"><span class="nav-number">4.</span> <span class="nav-text">3. TIMELY 结构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-RTT的测量"><span class="nav-number">4.1.</span> <span class="nav-text">3.1 RTT的测量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-速率计算引擎"><span class="nav-number">4.2.</span> <span class="nav-text">3.2 速率计算引擎</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-速率控制引擎"><span class="nav-number">4.3.</span> <span class="nav-text">3.3 速率控制引擎</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-TIMELY-拥塞控制"><span class="nav-number">5.</span> <span class="nav-text">4.TIMELY 拥塞控制:</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-度量和设置"><span class="nav-number">5.1.</span> <span class="nav-text">4.1 度量和设置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-基于延迟梯度的策略"><span class="nav-number">5.2.</span> <span class="nav-text">4.2 基于延迟梯度的策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#相关算法"><span class="nav-number">5.2.1.</span> <span class="nav-text">相关算法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-核心算法"><span class="nav-number">5.3.</span> <span class="nav-text">4.3 核心算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-梯度-VS-队列大小"><span class="nav-number">5.4.</span> <span class="nav-text">4.4 梯度 VS 队列大小</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-实际应用"><span class="nav-number">6.</span> <span class="nav-text">5. 实际应用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-传输界面"><span class="nav-number">6.1.</span> <span class="nav-text">5.1 传输界面</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-使用NIC完成进行RTT的测量"><span class="nav-number">6.2.</span> <span class="nav-text">5.2 使用NIC完成进行RTT的测量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-RDMA速率控制"><span class="nav-number">6.3.</span> <span class="nav-text">5.3 RDMA速率控制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4-应用限制行为"><span class="nav-number">6.4.</span> <span class="nav-text">5.4 应用限制行为</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-速率更新频率"><span class="nav-number">6.5.</span> <span class="nav-text">5.5 速率更新频率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-6-额外的【发送-pacing-？？？】机会"><span class="nav-number">6.6.</span> <span class="nav-text">5. 6 额外的【发送 pacing ？？？】机会</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-评估"><span class="nav-number">7.</span> <span class="nav-text">6. 评估</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-小规模实验"><span class="nav-number">7.1.</span> <span class="nav-text">6.1 小规模实验</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-1-测量的RTT必须精准："><span class="nav-number">7.1.1.</span> <span class="nav-text">6.1.1   测量的RTT必须精准：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-2-与PFC做比较："><span class="nav-number">7.1.2.</span> <span class="nav-text">6.1.2 与PFC做比较：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-3-和DCTCP的对比"><span class="nav-number">7.1.3.</span> <span class="nav-text">6.1.3 和DCTCP的对比</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-3-和TCP-FAST-like算法做对比"><span class="nav-number">7.1.4.</span> <span class="nav-text">6.1.3 和TCP FAST-like算法做对比</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-4-变化的Tlow"><span class="nav-number">7.1.5.</span> <span class="nav-text">6.1.4 变化的Tlow</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-5-使用细粒度的pacer调整使Burst更平滑"><span class="nav-number">7.1.6.</span> <span class="nav-text">6.1.5 使用细粒度的pacer调整使Burst更平滑</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-6-变化的Thigh"><span class="nav-number">7.1.7.</span> <span class="nav-text">6.1.6 变化的Thigh</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-7-激进增量（HAI）"><span class="nav-number">7.1.8.</span> <span class="nav-text">6.1.7 激进增量（HAI）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-大规模实验"><span class="nav-number">7.2.</span> <span class="nav-text">6.2 大规模实验</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-1-最长路径均匀随机"><span class="nav-number">7.2.1.</span> <span class="nav-text">6.2.1 最长路径均匀随机</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-2-网络不平衡-incast"><span class="nav-number">7.2.2.</span> <span class="nav-text">6.2.2 网络不平衡(incast)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-3-应用级别的标准"><span class="nav-number">7.2.3.</span> <span class="nav-text">6.2.3 应用级别的标准</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-相关工作"><span class="nav-number">7.3.</span> <span class="nav-text">7. 相关工作</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-总结"><span class="nav-number">8.</span> <span class="nav-text">8. 总结</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YiqingMa</span>

  
</div>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>





        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("0ixKT2BwaVfXNDSkwyzUoHme-gzGzoHsz", "EdAY2rFqeW0COVKGLhLtLEAp");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  

  

  


  <!-- 页面点击小红心 -->
  <script type="text/javascript" src="/js/src/love.js"></script>
  <!-- 背景动画 
  <script type="text/javascript" src="/js/src/particle.js"></script>-->
</body>
</html>
